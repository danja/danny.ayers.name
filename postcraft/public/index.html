<!DOCTYPE html>
<html lang="en">

<head>
    <title>Rawer</title>

    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="X-UA-Compatible" content="ie=edge">

    <!-- #:todo remove when stable -->
    <meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
    <meta http-equiv="Pragma" content="no-cache">
    <meta http-equiv="Expires" content="0">

    <link rel="stylesheet" href="/css/fonts.css" type="text/css" />
    <link rel="stylesheet" href="/css/grid-columns.css" type="text/css" />
    <link rel="stylesheet" href="/css/style.css" type="text/css" />
    <link rel="stylesheet" href="/css/menu.css" type="text/css" />

</head>

<body>
    <header id="main-header">
        <h1 class="h-title">
           Raw<em>er</em>
        </h1>
    </header>
    <div class="grid-container">
        <div class="main-grid-item directory">
            <p><strong>Under Construction</strong></p>
            <p></p>
        </div>
        <div class="main-grid-item articles">
            <article>
                <!-- ARTICLE CONTENT -->

<article class="post-content">
    <h1>Wave Function Collapse for Sounds</h1>
<p>Repo : <a href="https://github.com/danja/collapse-lv2">https://github.com/danja/collapse-lv2</a></p>
<p>I stumbled on <a href="https://github.com/mxgmn/WaveFunctionCollapse">WaveFunctionCollapse</a>, &quot;This program generates bitmaps that are locally similar to the input bitmap.&quot;. It occurred to me that the same algorithm might be usable on audio streams. I wrote a long prompt for <a href="https://www.deepseek.com/en">DeepSeek</a> which had a good long discussion with itself before producing the material below. This I passed to <a href="https://claude.ai/new">Claude chat</a> together with the instructions for it to make an <a href="https://en.wikipedia.org/wiki/LV2">LV2 plugin</a> for me. I want to use it in <a href="https://www.reaper.fm/">Reaper</a>, my DAW of choice.
(I&#39;ve already had a go at <strong>vibe coding</strong> with <a href="https://github.com/danja/amen-chaos">amen-chaos</a> and <a href="https://github.com/danja/midi-chaos-amen">midi-chaos-amen</a> with considerable success, as far as I took them). Claude gave me some patchy files which I stuck up at <a href="https://github.com/danja/collapse-lv2">GitHub</a> before setting <a href="https://www.anthropic.com/claude-code">Claude Code</a> on them.</p>
<p><del>So far I&#39;ve not got anything usable, I ran out of Claude tokens. Apparently <a href="https://codeassist.google/">Google Gemini</a> for coding is now free, so I may give that a shot later.</del> Gemini was slow. Went back to Claude and now <strong>it works!</strong></p>
<p>Anyhow, below is what DeepSeek gave me, it has the basic idea. <del>I&#39;ve a feeling it won&#39;t be any good without taking into account the periodicity of the input. This could potentially operate at the waveform level, or (depending on how it performs) over beats or bars. Dunno.</del></p>
<p>I added period detection with autocorrelation in at the start. It&#39;s very picky about which settings will actually produce a processed output. But it really messes things up, which is exactly what I was hoping for.</p>
<hr>
<p>To apply the wave function collapse (WFC) technique to audio waveforms in near real-time, we reinterpret the grid-based approach for time-series data. Here&#39;s a conceptual adaptation and JavaScript implementation:</p>
<h3>Core Concept Adaptation:</h3>
<ol>
<li><p><strong>Grid Representation</strong>:</p>
<ul>
<li><strong>X-axis</strong>: Represents time (one cycle or window of the waveform).</li>
<li><strong>Y-axis</strong>: Represents <strong>quantized amplitude levels</strong> (discrete buckets for continuous sample values).</li>
<li><strong>Z-axis (optional)</strong>: Encodes <strong>local patterns</strong> (e.g., sequences of amplitude changes).</li>
</ul>
</li>
<li><p><strong>Pattern Extraction</strong>:</p>
<ul>
<li>Slice the input waveform into overlapping windows (e.g., 10-sample segments).</li>
<li>Quantize amplitudes (e.g., 256 levels) to create discrete &quot;tiles&quot;.</li>
<li>Catalog valid neighbor transitions (e.g., which 10-sample blocks can follow each other).</li>
</ul>
</li>
<li><p><strong>Real-Time Generation</strong>:</p>
<ul>
<li>Maintain a &quot;collapsing&quot; buffer of recent samples (context window).</li>
<li>For each new sample, resolve constraints by selecting valid patterns that match the context.</li>
<li>Output the next sample from the chosen pattern.</li>
</ul>
</li>
</ol>
<hr>
<h3>JavaScript Implementation:</h3>
<pre><code class="language-javascript">class WaveformWFC {
  constructor(inputSamples, patternSize = 10, quantLevels = 256) {
    this.patternSize = patternSize;
    this.quantLevels = quantLevels;
    this.patterns = new Map(); // pattern -&gt; {nextPatterns: Set, count: number}

    // Quantize input [-1, 1] to discrete levels
    this.quantize = (sample) =&gt;
      Math.max(0, Math.min(quantLevels - 1,
        Math.floor((sample + 1) * quantLevels / 2)));

    this.dequantize = (level) =&gt;
      (level / (quantLevels - 1)) * 2 - 1;

    this.extractPatterns(inputSamples);
  }

  extractPatterns(samples) {
    // Build patterns from sliding windows
    for (let i = 0; i &lt; samples.length - this.patternSize; i++) {
      const window = samples.slice(i, i + this.patternSize);
      const quantPattern = window.map(s =&gt; this.quantize(s));
      const key = quantPattern.join(&#39;,&#39;);

      // Track pattern frequency and allowed successors
      if (!this.patterns.has(key)) {
        this.patterns.set(key, { nextPatterns: new Set(), count: 0 });
      }
      const data = this.patterns.get(key);
      data.count++;

      // Record valid next pattern (overlapping window)
      if (i &lt; samples.length - this.patternSize - 1) {
        const nextWindow = samples.slice(i + 1, i + this.patternSize + 1);
        const nextKey = nextWindow.map(s =&gt; this.quantize(s)).join(&#39;,&#39;);
        data.nextPatterns.add(nextKey);
      }
    }
  }

  generateSample(context) {
    // Quantize recent context (patternSize - 1 samples)
    const quantContext = context.map(s =&gt; this.quantize(s));
    const contextKey = quantContext.join(&#39;,&#39;);

    // Find patterns starting with current context
    const candidates = [];
    for (const [pattern, data] of this.patterns) {
      const patternArr = pattern.split(&#39;,&#39;).map(Number);
      const matchesContext = quantContext.every(
        (val, i) =&gt; val === patternArr[i]
      );

      if (matchesContext) {
        // Weight by occurrence frequency
        for (let i = 0; i &lt; data.count; i++) {
          candidates.push(patternArr[patternArr.length - 1]); // Last sample in pattern
        }
      }
    }

    // Fallback: Random sample if no candidates
    if (candidates.length === 0) {
      return Math.random() * 2 - 1; // [-1, 1]
    }

    // Random weighted selection
    const nextLevel = candidates[Math.floor(Math.random() * candidates.length)];
    return this.dequantize(nextLevel);
  }
}

// Usage Example
const audioContext = new AudioContext();
const inputSamples = [...]; // Float32Array from source audio

const wfc = new WaveformWFC(inputSamples);
const outputBuffer = new Float32Array(44100); // 1sec buffer
let context = new Array(wfc.patternSize - 1).fill(0); // Initial silence

for (let i = 0; i &lt; outputBuffer.length; i++) {
  outputBuffer[i] = wfc.generateSample(context);

  // Update context (remove oldest, add new sample)
  context.shift();
  context.push(outputBuffer[i]);
}

// Play generated audio
const buffer = audioContext.createBuffer(1, outputBuffer.length, 44100);
buffer.copyToChannel(outputBuffer, 0);
const source = audioContext.createBufferSource();
source.buffer = buffer;
source.connect(audioContext.destination);
source.start();
</code></pre>
<h3>Key Optimizations for Real-Time:</h3>
<ol>
<li><strong>Context Hashing</strong>:<ul>
<li>Precompute lookup tables for quantized context keys to candidate patterns.</li>
</ul>
</li>
<li><strong>Approximate Matching</strong>:<ul>
<li>Use Euclidean distance thresholds for noisy inputs.</li>
</ul>
</li>
<li><strong>Pattern Pruning</strong>:<ul>
<li>Discard low-frequency patterns to reduce state space.</li>
</ul>
</li>
<li><strong>Overlap Handling</strong>:<ul>
<li>Generate samples in blocks (e.g., 128 samples) to amortize lookup costs.</li>
</ul>
</li>
</ol>
<h3>How Structure is Preserved:</h3>
<ol>
<li><strong>Local Constraints</strong>:<ul>
<li>Transition rules enforce that amplitude sequences (e.g., attack-decay in notes) replicate input behaviors.</li>
</ul>
</li>
<li><strong>Global Coherence</strong>:<ul>
<li>Weighted pattern selection maintains statistical properties (e.g., amplitude distribution).</li>
</ul>
</li>
<li><strong>Continuity</strong>:<ul>
<li>Overlapping context buffers prevent discontinuities between generated segments.</li>
</ul>
</li>
</ol>
<p>This approach mirrors WFC&#39;s constraint-solving in a temporal domain, transforming input waveforms into novel outputs with similar micro/macro structures.
 </p>

</article>
<p class="post-title h-cinzel">
    <a href="http://danny.ayers.name/entries/wfc-synth.html">
        Wave Function Collapse for Sounds
    </a>
</p> <em></em><!-- ARTICLE CONTENT -->

<article class="post-content">
    <h1>Journal 2025-06-23</h1>
<h2>New Domain : tensegrity.it</h2>
<p>I&#39;ve added a new DNS domain to my collection, so I now have :</p>
<ol>
<li><a href="https://danny.ayers.name">danny.ayers.name</a> - my personal site (this blog)</li>
<li><a href="https://hyperdata.it">hyperdata.it</a> - my quasi-company site</li>
<li><a href="https://strandz.it">strandz.it</a> - for a project, in planning</li>
<li><a href="https://tensegrity.it">tensegrity.it</a> - my current raft of code projects</li>
</ol>
<p>They are all undeniably <strong>Under Construction</strong>.</p>
<p>The new one came about because I realised that my the things I&#39;m working on strongly resemble a <a href="https://en.wikipedia.org/wiki/Tensegrity">tensegrity structure</a>. Only after setting up a <a href="https://github.com/danja/tensegrity">GitHub repo</a> to record this did I think to check for the domain name. Right now the repo just contains a sketchy overview. I&#39;ll use the new domain for now just as a tech blog, keeping the <code>.name</code> domain for non-coding stuff.  
 </p>

</article>
<p class="post-title h-cinzel">
    <a href="http://danny.ayers.name/entries/2025-06-23_journal.html">
        Journal 2025-06-23
    </a>
</p> <em></em><!-- ARTICLE CONTENT -->

<article class="post-content">
    <h1>Simple Distortion Circuit</h1>
<p><a href="https://www.youtube.com/watch?v=mMDBcwWSbNc">rough demo video</a></p>
<p>I was a bit frustrated not having a convenient distortion module on my setup so I designed one. After a handful of sketches and a little bit of breadboarding, this is what I came up with :</p>
<p><img src="/images/2025-06/distortion.png" alt="Schematic"></p>
<p>Its operation is a lot more straightforward than it looks.</p>
<p>The left-hand op amp is just operating as a textbook inverting amp, gain of x1 to about x10. The right-hand hand op amp is having more fun. The core idea is that of a <a href="https://en.wikipedia.org/wiki/Log_amplifier">log amplifier</a>, the &quot;transdiode&quot; configuration. It&#39;s using the exponential characteristic of a bipolar transistor in the feedback of the op amp to achieve a logarithmic transfer function. In other words, <strong>soft clipping</strong>. Tube overdrive style, if you&#39;re an American guitar head. The magic part of this configuration is that the combination of NPN and PNP transistors, simply one on top of the other, actually works to make the function work on negative-going signals in mirror image. <em>No way that would work!</em> But it does.</p>
<p>I&#39;ve flipped the op amp inputs so this is non-inverting - I&#39;d forgotten, I was going to make the input amp non-inverting too... Reason being, ideally I wanted it DC-coupled so it could be an interesting function on control voltages too. But when wired up to modules this messed up its use on signals - the <em>your guess is as good as mine</em> Eurorack standard voltage levels. So I AC coupled it, hence the cap on input &amp; output. (The 100p cap in the feedback is my cargo cult attempt at ensuring HF stability. It makes no audible difference).</p>
<p>The variable resistance in the feedback effectively adjusts when the transistors start getting curvy. When it&#39;s down to the 10k I couldn&#39;t see or hear any difference from the input signal, is effectively unity gain. Wide open, the curve starts early, it sounds like hard clipping.</p>
<p>The pair of diodes was the result of messing about. I initially tried them from the signal path between the first op amp and the second, to ground. I expected a buzzier hard clipping at a lower level, until the log-ish follower was wound up for gain. But it wasn&#39;t very interesting. What was interesting is the current config. I&#39;ll leave it to someone better at sums than me to figure out properly, but intuitively I would have expected this to have extended the linearish low level region up by the voltage drop until transistor bias starts kicking in, with the effect of raising the curvy roof. Nah. The result in practice is that it gives an audible boost overall. When the bases are direct to ground, the transfer curve seems rather kinky, not as smooth as it should be. With the diodes in circuit, it have a much more elegant curve. My technical explanation is something something op amp compensating something bias something.</p>
<p>Here&#39;s it on the breadboard :</p>
<p><img src="/images/2025-06/breadboard.png" alt="Breadboard"></p>
<p>I&#39;ve got all the music room gear in the office while I redecorate, and the desktop machine I usually run a &#39;scope (Bitscope) on was busy entertaining Claude. So it gave me a chance to use my breadboard. It is literally built on a plastic breadboard, hat tip to the originators. As well as the horrid little Chinese scope and signal generator there&#39;s a home-hack audio amp, underneath a +/- 12v, +5 PSU in a tin I got from Penny Market. Got 3.5 mm sockets, various pots, a few switches. The idea is I can take prototypes to the modular in a Mohammed-mountain kind of deal. Only after I&#39;d made it did I hear about the Erica Synths (they who do collabs with the wonderful DIYer <a href="https://www.youtube.com/@MoritzKlein0">Moritz Klein</a>) do a ready-made, neat version : the <a href="https://www.ericasynths.lv/shop/diy-kits-1/edu-diy-labor/">EDU DIY Labor</a>. Hey ho. Saved meself a few quid.</p>
<p>Oh yeah, back to the circuit. Nothing&#39;s critical. For op amps I used a TL072, transistors a BC109 &amp; BC179, generic highish gain silicon small signal I happened to have. To keep it balanced up &amp; down you probably want a complementary pair like that. I plan to slap the circuit on a scrap of stripboard, cut &amp; drill a bit of aluminium sheet for front panel, couple of hours work max, my itch scratched.
 </p>

</article>
<p class="post-title h-cinzel">
    <a href="http://danny.ayers.name/entries/simple-distortion-circuit.html">
        Simple Distortion Circuit
    </a>
</p> <em></em><!-- ARTICLE CONTENT -->

<article class="post-content">
    <h1>Journal 2025-06-16</h1>
<h2>Idea Generation from Imagined Acronym Expansions</h2>
<p><img src="/images/2025-06/zpt-rube.png" alt="cartoon of this post"></p>
<p>Claude is funny. I&#39;m putting together a knowledgebase navigation system based on an ontology, <a href="https://github.com/danja/zpt">ZPT</a> for use in <a href="https://github.com/danja/semem">Semem</a> (not <em>semen</em>).
I&#39;ve go the under-the-hood pieces mostly in place, right now Claude &amp; I are looking at <a href="https://modelcontextprotocol.io/introduction">Model Control Protocol</a> (not <em>male chauvinist pig</em>) access.</p>
<p>ZPT is <strong>Zoom, Pan, Tilt</strong>, using a camera metaphor for looking at knowledge. Claude doesn&#39;t like that acronym expansion. When I&#39;ve had it write docs it prefers <strong>&quot;Zero-point traversal&quot;</strong> which sounds like a thing, maybe from around graph theory, or <em>quantum</em>, but as far as I can tell, <em>isn&#39;t</em>. Just now Claude gave me another : <strong>&quot;Zero-Prompt Templates&quot;</strong>. Again it sounds like a thing, like <em>zero-shot prompting</em> is, but, nah. Claude made it up.</p>
<p>Now I must to know what these things are.  
 </p>

</article>
<p class="post-title h-cinzel">
    <a href="http://danny.ayers.name/entries/2025-06-16_journal.html">
        Journal 2025-06-16
    </a>
</p> <em></em><!-- ARTICLE CONTENT -->

<article class="post-content">
    <h1>Journal 2025-06-14</h1>
<h2>Remind me why I&#39;m doing this...</h2>
<p>I had one of those moments just now. I&#39;ve intermittently put a lot of time into <a href="https://github.com/danja/semem">Semem</a>, my <em>Semantic Memory</em> thing. The sessions have got increasingly intense, it went something like this :</p>
<ol>
<li><strong>Rough scaffolding implementation</strong> - a setup that included embeddings for <em>semantic search</em> plus using an LLM for concept extraction. It also had a bit of support for a temporal dimension, short-term &amp; long-term memory (I lifted what I could from the design of <a href="https://github.com/caspianmoon/memoripy">Memoripy</a>, given I&#39;m using Node JS). I got a SPARQL store client in there, but wasn&#39;t really doing anything with it at this stage, data was mostly JSON.</li>
<li><strong><a href="https://github.com/danja/ragno">Ragno</a> ontology design</strong> - I needed a <strong>model of a knowledgebase</strong> to build from. I went through several back-of-envelope cycles with it, the usual malarky of trying to pin things down to keep some semblence of control while still leaving things open enough to allow serendipity to play. Then I stumbled on the <a href="https://github.com/Terry-Xu-666/NodeRAG">NodeRAG</a> paper. Aha! <em>This</em> is what I want. Except they had things quite tightly pinned down, and the notion of <strong>non-retrievable resources</strong> on the Semantic Web? <strong>Nah.</strong> So I kinda merged the floppy thing I already had with this more rigid thing, implemented the basic structures.
A huge bonus with the paper was that it outlines a bunch of different algorithms for working with knowledgebases.</li>
<li><strong>Ragno implementation</strong> - with considerable help from Claude I set about implementing them in the Semem environment. Lots of cycles. Claude is such a fibber about when things are complete &amp; working. After a long journey through the gaslighting, I believe most, if perhaps not all, work.</li>
<li><strong><a href="https://github.com/danja/zpt">ZPT</a> ontology design</strong> - that&#39;s <strong>Zoom, Pan, Tilt</strong>, not as Claude kept insisting in the docs <strong>Zero-point traversal</strong>. I looked that up, very much expecting it to be a thing, it makes sense for a curve, though <em>traversal</em> hints at this other form of graphs. Apparently not. Claude&#39;s imagination. <em>If it becomes a thing in <strong>quantum</strong> in the next year or two, I&#39;m joining a monastery.</em> <strong>Zoom, Pan, Tilt</strong> is for <strong>knowledgebase navigation</strong>, using those cinematic analogies. I&#39;d had it sketched out for a while. Finding the NodeRAG paper was also serendipitous in helping me think about this separately from the core knowledgebase description. (<strong>foraging for the win!</strong>) Maybe not orthogonally, but at least loosely-coupled.
Being still fresh from the Ragno implementation I rolled with the momentum, got this bashed out. Again, I believe it <em>mostly</em> works - all the demo scripts (under <a href="https://github.com/danja/semem/tree/main/examples">examples/</a>) have worked at least once. <em>Heh, except those under <code>pending</code>, haven&#39;t a clue where I&#39;m up to with those.</em></li>
<li><strong>MCP Implementation</strong> - I&#39;d already got approximate HTTP API endpoints in place (along with very sketchy UI for trying things out), and even a first-pass, untested MCP. But it became increasingly obvious this was something I needed to do a bit more properly. Dual function : selectively expose the stuff under the hood for sanity-checking, plus <strong>it might actually be useful</strong>.</li>
</ol>
<p>Which brings me back to my starting point. <strong>Useful for what..?!</strong></p>
<p>I spend so much time making tools to make tools (ditto in real life) I forgot the original motivation.</p>
<p><em>Benchmarks! The primary goal of all modern software!</em></p>
<p>Ok, that was it, <strong>Personal Knowledge Management</strong>. Which may be project specific, relatively narrow domain. Not one size fits all. I play around with music and associated technology, have all kinds of other little hobby (and house-related) projects on the go. I&#39;ve <em>thousands</em> of bookmarked links relating to this stuff. I&#39;ve got loads of my own notes scattered all over the place, backups of intermittent blog posting going back a couple of decades. This is all knowledge that could potentially help me with my activities, if only I could access it in a useful way.</p>
<p>Yeah, so. How do I get all the material into my <em>soon to be</em> knowledgebase? Well, the other project I&#39;ve been putting the <em>other</em> bulk of my time into is <a href="https://github.com/danja/transmissions">Transmissions</a>, a pipeliney thing into for just such operations. That too is mostly in place/rather fragile in places.</p>
<p>I&#39;m going to be spending the next few weeks (until 2025-07-03) at least making a note of loose strings in my <a href="https://github.com/danja/tensegrity">tensegrity structure of projects</a>. Then I&#39;m going to try to avoid this stuff for a month.  </p>
<p>Wish me luck.</p>
<p>PS. I have a <strong>Use Case</strong> : use Semem to help write a paper about...<strong>Semem!</strong> #:dogfood
 </p>

</article>
<p class="post-title h-cinzel">
    <a href="http://danny.ayers.name/entries/2025-06-14_journal.html">
        Journal 2025-06-14
    </a>
</p> <em></em>
            </article>
        </div>
        <div class="main-grid-item about">
            <!--
            <h2>About</h2>
            
            -->
        </div>
    </div>
    <script src="js/menu.js"></script>
</body>

</html>